---
title: 'Mineria de dades: PAC2'
author: "Autor: Nom estudiant"
date: "Abril 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 05.584-PAC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*****
# Introducció
*****
## Presentació
Aquesta prova d'avaluació continuada cobreix els mòduls 5 i 6 del programa de l'assignatura.

## Competències
Les competències que es treballen en aquesta prova són:

* Ús i aplicació de les TIC en l'àmbit acadèmic i professional
* Capacitat per a innovar i generar noves idees.
* Capacitat per a avaluar solucions tecnològiques i elaborar propostes de projectes tenint en compte els recursos, les alternatives disponibles i les condicions de mercat.
* Conèixer les tecnologies de comunicacions actuals i emergents, així com saber-les aplicar convenientment per a dissenyar i desenvolupar solucions basades en sistemes i tecnologies de la informació.
* Aplicació de les tècniques específiques d'enginyeria del programari en les diferents etapes del cicle de vida d'un projecte.
* Capacitat per a aplicar les tècniques específiques de tractament, emmagatzematge i administració de dades.
* Capacitat per a proposar i avaluar diferents alternatives tecnològiques per a resoldre un problema concret.
* Capacitat d'utilitzar un llenguatge de programació.
* Capacitat per a desenvolupar en una eina IDE.
* Capacitat de plantejar un projecte de mineria de dades.

## Objectius
En aquesta PAC treballarem la generació, interpretació i avaluació d'un model d'agregació i d'un model on generarem regles d'associació amb el programari de practiques. No perdrem de vista les fases de preparació de les dades, qualitat del model i extracció inicial del coneixement.

## Descripció de la PAC a realitzar
La prova està estructurada en 2 exercicis teòrics i 3 exercicis pràctics.

## Recursos
Per a realitzar aquesta pràctica recomanem com a punt de partida la lectura dels següents documents:

* Mòdul 5 i 6 del material didàctic.
* L'aula laboratori de R per resoldre dubtes o problemes.
* RStudio Cheat Sheet: Disponible a l'aula Laboratori de Mineria de dades.
* R Base Cheat Sheet: Disponible a l'aula Laboratori de Mineria de dades.


## Format i data de lliurament
El format de lliurament és: usernameestudiant-PAC1.html (pdf o word) i rmd. 
Data de Lliurament: 21/04/2021.
S'ha de lliurar la PAC en la bústia de lliuraments de l'aula.


## Nota: Propietat intel·lectual

Sovint és inevitable, en produir una obra multimèdia, fer ús de recursos creats per terceres persones. És per tant comprensible fer-ho en el marc d'una pràctica dels estudis d'Informàtica, Multimèdia i Telecomunicació de la UOC, sempre que això es documenti clarament i no suposi plagi en la pràctica.

Per tant, en presentar una pràctica que faci ús de recursos aliens, s'ha de presentar juntament amb ella un document en què es detallin tots ells, especificant el nom de cada recurs, el seu autor, el lloc on es va obtenir i el seu estatus legal: si l'obra està protegida pel copyright o s'acull a alguna altra llicència d'ús (Creative Commons, llicència GNU, GPL ...).
L'estudiant haurà d'assegurar-se que la llicència no impedeix específicament el seu ús en el marc de la pràctica. En cas de no trobar la informació corresponent haurà d'assumir que l'obra està protegida per copyright.

Haureu, a més, adjuntar els fitxers originals quan les obres utilitzades siguin digitals, i el seu codi font si correspon.

*****
# Exercici 1
*****

## Enunciat
1. Explica de forma resumida quin és l'objectiu dels mètodes d'agregació. Relaciona la resposta amb un exemple.
2. Raona si té sentit aplicar un mètode d'agregació a l'exemple que vas posar en la PAC1. Si ho té, comenta com es podria aplicar i que tipus de resultats es podrien obtenir. Si no ho té, reformula el problema perquè si el tingui.

## Resposta exercici 1
Els mètodes d'agregació ens permeten trobar les diferents classes d'elements que ens podem trobar dins d'un mateix domini. Així doncs el seu objectiu principal és del de generar una llista de grups a través d'un conjunt d'elements d'entrada que es troben descrits per una col·lecció d'atributs.
Quan realitzem aquesta llista de grups respecte als valors d'entrada, els mètodes d'agregació ens permeten crear diferents subconjunts d'elements similars, com podria ser el cas dels diferents tipus de  clients d'un negoci. 


**Definició del projecte de la PAC1**:

Enfocat en el camp de les assegurances. Suposem que som una empresa d'assegurances bastant gran i que té pòlisses d'assegurances de cotxes de múltiples parts de Catalunya. Així doncs les dades que obtenim provenen de diferents territoris. La tasca principal d'aquest projecte és la de predir el risc que té la nostra empresa d'assegurances respecte a la pòlissa un client.

Amb l'exemple que es va proposar a la PAC1 tindria sentit aplicar mètodes d'agregació. La font de dades que disposaríem per a cada element seria un conjunt d'atributs que s'utilitzarien per realitzar el 'clustering'. A través de l'aplicació d'aquests mètodes, podríem obtenir diferents grups de clients a partir de les combinacions dels diferents atributs i valors proporcionats per a cada un d'aquests sense imposar un criteri a priori. 

El còmput d'aquests diferents clústers, pot ser un pas que ens serveixi extreure conclusions sobre quins tendeixen a ser els factors diferencials d'un major risc d'una pòlissa.

*****
# Exercici 2
*****
## Enunciat
1. Explica de forma resumida quin és l'objectiu dels mètodes de generació de regles d'associació. Relaciona la resposta amb un exemple.
2. Raona si té sentit aplicar un mètode de generació de regles d'associació a l'exemple que vas posar en la PAC1. Si ho té, comenta com es podria aplicar i que tipus de resultats es podrien obtenir. Si no ho té, reformula el problema perquè si el tingui.

## Resposta exercici 2
Les regles d’associació són un conjunt d’expressions que construeixen un model que ens serveixen per descriure un domini segons les dependències entre els valors dels atributs d’un conjunt de dades. Així doncs, podem determinar que la seva funció principal és la de descobrir patrons o regles per tal de saber quins són els tipus d’episodis freqüents que succeeixen.

Centrant-nos en el cas de la PAC1, tindria molt de sentit aplicar mètodes de generació de regles d’associació. Aquests ens podrien ser útils per poder descobrir quins són els patrons o regles que trobem en el conjunt de dades de la nostra asseguradora, tal que donades unes característiques de qualitat, es trobin associades amb el risc de cada una de les pòlisses.


*****
# Exercici 3
*****
## Enunciat
En aquest exercici seguireu els passos del cicle de vida d'un projecte de mineria de dades per al cas d'un algorisme d'agregació. Ho fareu amb el fitxer clients.csv que trobareu adjunt. Cal no oblidar-se de la fase de preparació i anàlisi de dades. És molt important explicar molt bé els resultats obtinguts.

Els exemples 1 i 2 es poden prendre com un punt de partida per a la realització d'aquest exercici, però s'espera que la resposta proporcionada tingui una anàlisi més àmplia al mostrat en aquests exemples, prestant especial atenció a explicar el coneixement que s'ha adquirit després del procés de mineria de dades.


## Exemple 1: Mètodes d'agregació amb dades autogenerades
En aquest exemple generarem un conjunt de mostres aleatòries per a posteriorment usar l'algorisme kmeans per a agrupar-les. Es crearan les mostres al voltant de dos punts concrets. Per tant, el lògic serà agrupar en dos clústers. Com que inicialment, en un problema real, no es coneix quin és el nombre més idoni de clústers k, provarem primer amb 2 (el valor òptim) i posteriorment amb 4 i 8 clústers. Per a avaluar la qualitat de cada procés d'agregació usarem la silueta mitjana. La silueta de cada mostra avalua com de bé o malament està classificada la mostra en el clúster al qual ha estat assignada. Per a això s'usa una fórmula que té en compte la distància a les mostres del seu clúster i la distància a les mostres del clúster veí més pròxim.

A l'hora de provar el codi que es mostra, és important tenir en compte que les mostres es generen de manera aleatòria i també que l'algorisme kmeans té una inicialització aleatòria. Per tant, en cada execució s'obtindrà uns resultats lleugerament diferents.

El primer que fem és carregar la llibreria clúster que conté les funcions que es necessiten.

```{r message= FALSE, warning=FALSE}
library(cluster)
```

Generem les mostres de manera aleatòria prenent com a centre els punts [0,0] i [5,5].

```{r message= FALSE, warning=FALSE}
n <- 150 # nombre de mostres
p <- 2   # dimensió

sigma <- 1 # variància de la distribució
mean1 <- 0 # centre del primer grup
mean2 <- 5 # centre del segon grup

n1 <- round(n/2) # nombre de mostres del primer grup
n2 <- round(n/2) # nombre de mostres del segon grup

x1 <- matrix(rnorm(n1*p,mean=mean1,sd=sigma),n1,p)
x2 <- matrix(rnorm(n2*p,mean=mean2,sd=sigma),n2,p)
```

Ajuntem totes les mostres generades i les mostrem en una gràfica

```{r message= FALSE, warning=FALSE}
x  <- rbind(x1,x2)
plot (x)
```

Com es pot comprovar les mostres estan clarament separades en dos grups. Si es vol complicar el problema es pot modificar els punts centrals (mean1 i mean2) fent que estiguin més pròxims i/o ampliar la variància (sigma) perquè les mostres estiguin més disperses.

A continuació aplicarem l'algorisme kmeans amb 2, 4 i 8 clústers.

```{r message= FALSE, warning=FALSE}
fit2       <- kmeans(x, 2)
y_cluster2 <- fit2$cluster

fit4       <- kmeans(x, 4)
y_cluster4 <- fit4$cluster

fit8       <- kmeans(x, 8)
y_cluster8 <- fit8$cluster
```

Les variables y_cluster2, y_cluster4 i y_cluster8 contenen per a cada mostra l'identificador del clúster a les quals han estat assignades. Per exemple, en el cas dels k=2 les mostres s'han assignat al clúster 1 o al 2.

```{r message= FALSE, warning=FALSE}
y_cluster2
```

Per a visualitzar els clústers podem usar la funció clusplot. Veiem l'agrupació amb 2 clústers

```{r message= FALSE, warning=FALSE}
clusplot(x, fit2$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Amb 4

```{r message= FALSE, warning=FALSE}
clusplot(x, fit4$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

i amb 8

```{r message= FALSE, warning=FALSE}
clusplot(x, fit8$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

També podem visualitzar el resultat del procés d'agregació amb el següent codi per al cas de 2 clústers

```{r message= FALSE, warning=FALSE}
plot(x[y_cluster2==1,],col='blue', xlim=c(min(x[,1]), max(x[,1])), ylim=c(min(x[,2]), max(x[,2])))
points(x[y_cluster2==2,],col='red')
```

per a 4

```{r message= FALSE, warning=FALSE}

plot(x[y_cluster4==1,],col='blue', xlim=c(min(x[,1]), max(x[,1])), ylim=c(min(x[,2]), max(x[,2])))
points(x[y_cluster4==2,],col='red')
points(x[y_cluster4==3,],col='green')
points(x[y_cluster4==4,],col='black')
```

i per a 8

```{r message= FALSE, warning=FALSE}
plot(x[y_cluster8==1,],col='blue', xlim=c(min(x[,1]), max(x[,1])), ylim=c(min(x[,2]), max(x[,2])))
points(x[y_cluster8==2,],col='red')
points(x[y_cluster8==3,],col='green')
points(x[y_cluster8==4,],col='black')
points(x[y_cluster8==5,],col='yellow')
points(x[y_cluster8==6,],col='purple')
points(x[y_cluster8==7,],col='cyan')
points(x[y_cluster8==8,],col='orange')
```

Ara avaluarem la qualitat del procés d'agregació. Per a això usarem la funció silhouette que calcula la silueta de cada mostra

```{r message= FALSE, warning=FALSE}
d  <- daisy(x) 
sk2 <- silhouette(y_cluster2, d)
sk4 <- silhouette(y_cluster4, d)
sk8 <- silhouette(y_cluster8, d)
```

La funció silhouette retorna per a cada mostra, el clúster on ha estat assignat, el clúster veí i el valor de la silueta. Per tant, calculant la mitjana de la tercera columna podem obtenir una estimació de la qualitat de l'agrupament

```{r message= FALSE, warning=FALSE}
mean(sk2[,3])
mean(sk4[,3])
mean(sk8[,3])
```

Com es pot comprovar, agrupar amb 2 clúster és millor que en 4 o en 8, la qual cosa és lògic tenint en compte com s'han generat les dades.

En aquest exercici no podem treure cap conclusió a partir dels clústers obtinguts perquè les dades de partida no es corresponen amb cap problema real. En un exemple real hauríem d'analitzar les agrupacions obtingudes per a obtenir coneixement sobre el problema a resoldre.

## Exemple 2: Mètodes d'agregació amb dades reals

A continuació veurem un altre exemple de com s'usen els models d'agregació. Per a això usarem el fitxer *flores.csv* que trobareu adjunt.

Carreguem el fitxer i visualitzem l'estructura de les dades.

```{r message= FALSE, warning=FALSE}
library(cluster)
flores_data<-read.csv("flores.csv", header=T, sep=",")
colnames(flores_data) <- c("sepalLength", "sepalWidth", "petalLength", "petalWidth")
summary(flores_data)
```

Com podem comprovar tenim quatre característiques, la longitud i amplària del sèpal i la longitud i amplària del pètal.

Com inicialment no coneixem el nombre òptim de clústers, provem amb diversos valors

```{r message= FALSE, warning=FALSE}
d <- daisy(flores_data) 
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(flores_data, i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}
```

Mostrem en un gràfica els valors de les siluetes mitjana de cada prova per a comprovar quin nombre de clústers és el millor

```{r message= FALSE, warning=FALSE}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Silueta")
```

El millor valor que s'obté és k=2.

Un altre manera d'avaluar quin és el millor nombre de clústers és considerar el millor model aquell que ofereix la menor suma dels quadrats de les distàncies dels punts de cada grup respecte al seu centre (withinss), amb la major separació entre centres de grups (betweenss). Com es pot comprovar és una idea conceptualment similar a la silueta. Una manera comuna de fer la selecció del nombre de clústers consisteix a aplicar el mètode elbow (colze), que no és més que la selecció del nombre de clústers sobre la base de la inspecció de la gràfica que s'obté en iterar amb el mateix conjunt de dades per a diferents valors del nombre de clústers. Se seleccionarà el valor que es troba en el "colze" de la corba.

```{r message= FALSE, warning=FALSE}
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(flores_data, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="tot.tot.withinss")
```

En aquest cas el nombre òptim de clústers és 3 o 4 que és quan la corba comença a estabilitzar-se.

També es pot usar la funció *kmeansruns* del paquet fpc que executa l'algorisme kmeans amb un conjunt de valors, per a després seleccionar el valor del nombre de clústers que millor funcioni d'acord amb dos criteris: la silueta mitjana ("asw") i Calinski-Harabasz ("ch").

```{r message= FALSE, warning=FALSE}
library(fpc)
fit_ch  <- kmeansruns(flores_data, krange = 1:10, criterion = "ch") 
fit_asw <- kmeansruns(flores_data, krange = 1:10, criterion = "asw") 
```

Podem comprovar el valor amb el qual s'ha obtingut el millor resultat i també mostrar el resultat obtingut per a tots els valors de k fent servir tots dos criteris

```{r message= FALSE, warning=FALSE}
fit_ch$bestk
fit_asw$bestk

plot(1:10,fit_ch$crit,type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Criteri Calinski-Harabasz")
plot(1:10,fit_asw$crit,type="o",col="blue",pch=0,xlab="Nombre de clústers",ylab="Criteri silueta mitjana")

```


Els resultats són molt semblants als que hem obtingut anteriorment. Amb el criteri de la silueta mitjana s'obtenen 2 clústers i amb el Calinski-Harabasz s'obtenen 3.

Com s'ha comprovat, conèixer el nombre òptim de clústers no és un problema fàcil. Tampoc ho és l'avaluació dels models d'agregació.

Després de les proves que hem realitzat per a obtenir el nombre òptim de clústers, hem trobat que el nombre de clústers varia segons el mètode entre 2, 3 o 4. Estudiarem els resultats trobats amb 2 i 3 clústers.

A continuació mostrarem visualment els clústers trobats suposant que hi ha 3 clústers. Cal tenir en compte que ens és possible mostrar els clústers en un espai de 4 dimensions. Per tant, mostrarem els clústers entre parells de característiques:

```{r message= FALSE, warning=FALSE}
cl3 <- kmeans(flores_data, 3)
with(flores_data, pairs(flores_data, col=c(1:4)[cl3$cluster])) 
```

La gràfica (que pot canviar d'una execució a una altra pel factor aleatori del kmeans) mostra clarament que hi ha un clúster que està més diferenciat dels altres dos.

Una bona tècnica que ajuda a entendre els grups que s'han format, és analitzar les característiques de cada grup:

* Grup 1: Valors del pètal alt. Longitud del sèpal alt.
* Grup 2: Valors del pètal baixos. Longitud del sèpal baix.
* Grup 3: Valors intermedis excepte en l'ample del sèpal que és intermedi.

Anem a ara a estudiar els conjunts que s'han obtingut amb 2 clústers:

```{r message= FALSE, warning=FALSE}
cl2 <- kmeans(flores_data, 2)
with(flores_data, pairs(flores_data, col=c(1:4)[cl2$cluster])) 
```

En aquest cas es comprova que existeixen dos grups amb un frontera bastant clara i que amb els valors del pètal tenim suficient per a diferenciar els dos grups. Podem descriure els dos grups com:

* Grup 1: Valors del pètal baixos.
* Grup 2: Valors del pètal alt.

Això últim ho podem comprovar usant únicament les dues característiques relacionades amb el pètal:

```{r message= FALSE, warning=FALSE}
cl2b <- kmeans(flores_data[c(3,4)], 2)
plot(flores_data[c(3,4)], col=cl2b$cluster)

```

## Mètodes d'agregació - clientes.csv

En aquest exerici utilitzarem models d'agregació respecte un conjunt de dades de clients. És per això que inicialment carregarem les dades del fitxer _clientes.csv_ i visualitzarem la seva estructura. 

```{r message= FALSE, warning=FALSE}
clients<-read.csv("clientes.csv", header=T, sep=",")
colnames(clients) <- c("customerID", "gender", "age", "annualIncome","spendingScore")
str(clients)
summary(clients)
```

Mitjançant la funció de 'summary' podem observar que el nostre conjunt de dades consta de 5 atributs. 
Seguidament farem una nateja ràpida dels possibles valors NA i modificarem el valor de _gender_ amb un 0 pel valor "Male" i 1 pel valor "Female".


```{r message= FALSE, warning=FALSE}
#Count NA elements and drop that rows
library(tidyr)

colSums(is.na(clients))
#clients %>% drop_na()

#We set the gender to a numeric value
#https://stackoverflow.com/questions/50241383/genre-sex-to-numeric-in-r/50241450
clients$gender <- ifelse(clients$gender=="Male", 0,1)
```
A continuació visualitzem a través d'un gràfic els valors de les siluetes mitjana per determinar quin és el millor nombre de clústers amb la llibreria _kmeans_ mitjançant la distància euclidiana. 

```{r message= FALSE, warning=FALSE}
d <- daisy(clients) 
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(na.omit(clients), i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}

plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nº of clusters",ylab="Silhouette")
```

Tal com poder visualtizar en el gràfic el millor valor que obtenim és amb un total de 2 clústers. (La gràfica pot ser canviant entre execucions el factor aleatori que trobem al mètode de _k-means_)

Seguidament visualitzarem com quedarien aquests dos conjunts:

```{r message= FALSE, warning=FALSE}
fit2 <- kmeans(clients, 2)
y_cluster2 <- fit$cluster

clusplot(clients, fit2$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Amb el gràfic anterior, podem observar que els dos conjunts resultants tenen una part sobreposada. És per això que provarem d'avaluar quin és el millor nombre de clústers pel nostre conjunt de dades mitjançant la menor suma dels quadrats de les distàncies dels punts de cada grup respecte al seu centre.

```{r message= FALSE, warning=FALSE}
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(clients, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Nº of clusters",ylab="Total within-cluster sum of squares")

```

Podem que quan els valors comencen a ser més estables amb el nombre de clústers 3 o 4, així doncs podria ser un bon punt de partida per analitzar.
Tot i això, també existeix la funció _kmeansruns_ dins del paquet _fpc_, que calcula el millor valor de nombre de clústers segons dos criteris diferents: 

* Silueta mitjana (“asw”)
* Calinski-Harabasz (“ch”)

```{r message= FALSE, warning=FALSE}
library(fpc)
fit_ch  <- kmeansruns(clients, krange = 1:10, criterion = "ch") 
fit_asw <- kmeansruns(clients, krange = 1:10, criterion = "asw") 
```

El paràmetre que ens indica el millor _k_ per a cada un dels dos criteris, es troba de la següent manera:

```{r message= FALSE, warning=FALSE}
#Criteri ASW
print(fit_asw$bestk)

#Criteri CH
print(fit_ch$bestk)

```

Els valors obtinguts mitjançant aquests dos criteris són molt similars als obtinguts anteriorment, tot i això observem que el càlcul del nombre òptim de clústers no és un problema senzill, ja que depenent el mètode aplicat hem obtingut resultats diferents.

A continuació realitzarem la visualització dels clústers suposants que n'hi ha 2. Donat que tenim 5 dimensions, les haurem de visualitzar dues a dues.

```{r message= FALSE, warning=FALSE}
cl2 <- kmeans(clients, 2)
with(clients, pairs(clients, col=c(1:5)[cl2$cluster])) 
```


Mitjançant aquest conjunt de gràfics podem extreure diferents conclusions:

* Relació directa entre l'edat i el 'Annual Income'.
* El client mitjà en qüestió de 'Spending Score' es trobaria a la franja d'edat d'entre els 40 i 60 anys.
* El client que tendeix a tenir un 'Spending Score' major és el que té entre 20 i 40 anys. 



```{r message= FALSE, warning=FALSE}
```

*****
# Exercici 4
*****
## Enunciat
En aquest exercici seguireu els passos del cicle de vida d'un projecte de mineria de dades per al cas d'un algorisme de generació de regles d'associació. Ho fareu amb el fitxer *Lastfm.csv* que trobareu adjunt. Aquest fitxer conté un conjunt de registres de l'històric de les cançons que ha escoltat un usuari en un portal Web de música. "artist" és el nom del grup que ha escoltat, "sex" i "country" corresponen a variables que descriuen a l'usuari.

L'exemple 3 es poden prendre com un punt de partida per a la realització d'aquest exercici, però s'espera que la resposta proporcionada tingui una anàlisi més àmplia al mostrat en aquest exemple, prestant especial atenció a explicar el coneixement que s'ha adquirit després del procés de mineria de dades.


## Exemple 3: Mètodes de generació de regles d'associació
En aquest exemple anem treballar l'algorisme "apriori" per a obtenir regles d'associació a partir d'un data set. Aquestes regles ens ajudaran a comprendre com la informació del data set es relaciona entre si.

Per a aquest objectiu treballarem el dataset de Groceries, que ja ve inclòs amb les llibreries de arules.

```{r message= FALSE, warning=FALSE}
# install.packages("arules")
library(arules)
data("Groceries")
```

Per a saber més sobre aquest dataset executar el comando "?Groceries".

Inspeccionem el dataset i veiem que té un llistat d'elements que van ser comprats junts. Ho analitzarem una mica visualment.

```{r message= FALSE, warning=FALSE}
inspect(head(Groceries, 5))
```

En el següent plot podem veure que els tres elements més venuts són la llet sencera, altres verdures i brioixeria. Donada la simplicitat del Dataset no es poden fer molt més anàlisi. Però per a datasets més complexos miraríem la freqüència i distribució de tots els camps, a la recerca de possibles errors.

```{r message= FALSE, warning=FALSE}
itemFrequencyPlot(Groceries,topN=20,type="absolute")
```

Si llancem l'algorisme "apriori", generarem directament un set de regles amb diferent suport, confiança i lift. El suport indica quantes vegades s'han trobat les regles {lsh => rhs} en el dataset, com més alt millor. La confiança parla de la probabilitat que {rhs} es doni en funció de {lhs}. I el lift és un paràmetre que ens indica quant d'aleatorietat hi ha en les regles. Un lift d'1 o menys és que les regles són completament fruit de l'atzar.

```{r message= FALSE, warning=FALSE}
grocery_rules <- apriori(Groceries, parameter = list(support = 0.01, confidence = 0.5))

inspect(head(sort(grocery_rules, by = "confidence"), 3))
```

Podem provar d'ordenar les regles pels diferents paràmetres, per a veure quina informació podem obtenir.

```{r message= FALSE, warning=FALSE}
inspect(head(sort(grocery_rules, by = "support"), 3))
```

Ordenant per support veiem que, amb un lift de 2 i una confiança del 51%, podem dir que la gent que en la mateixa compra feia verdures i iogurt, compraven també llet sencera. Cal tenir en compte que la llet sencera és d'altra banda l'element més venut de la botiga.

```{r message= FALSE, warning=FALSE}
inspect(head(sort(grocery_rules, by = "lift"), 3))
```

D'altra banda, si ordenem per lift, veiem que amb un suport de l'1% i una confiança del 58%, la gent que compra cítrics i tubercles compra també verdures.

Aquesta informació ens pot ajudar a donar consells a la direcció de la disposició dels elements a la botiga o que productes posar en oferta segons el que s'ha comprat. I si tinguéssim més informació podríem fer anàlisis més profundes i veure que clients compren exactament què.

## Mètodes d'associació - lastfm.csv



```{r message= FALSE, warning=FALSE}
lastfm<-read.csv("lastfm.csv", header=T, sep=",")

#We count NA values - 0 NA
colSums(is.na(lastfm))

#We set the gender to a numeric value
clients$gender <- ifelse(clients$gender=="m", 0,1)

```

*****
# Exercici 5
*****
## Enunciat
Cerca informació sobre altres mètodes d'agregació diferents al *k-means*. Partint de l'Exercici 3, provar el funcionament d'almenys 2 mètodes diferents i comparar els resultats obtinguts.

## Resposta exercici 5
### K-nearest Neighbours

El mètode de K-nearest Neighours és una proposta diferent del _k-means_ provat anteriorment, que es bassa en calcular la proximitat entre grups mitjançant la similitud entre objectes.

**Implementació** : 

Inicialment carreguem de nou les dades.
```{r message= FALSE, warning=FALSE}
lastfm<-read.csv("lastfm.csv", header=T, sep=",")

#We count NA values - 0 NA
colSums(is.na(lastfm))

#We set the gender to a numeric value
lastfm$sex <- ifelse(lastfm$sex=="m", 0,1)

```

```{r message= FALSE, warning=FALSE}
library(arules)
#inspect(head(lastfm, 5))
```



*****
# Criteris d'avaluació
*****

## Exercici 1 (20%)
* 60%. Explicar de forma resumida com és l'objectiu dels mètodes d'agregació. Relacionar la resposta amb un exemple.
* 40%. Raonar si té sentit aplicar un mètode agregació a l'exemple que vas posar en la PEC1. Si ho té, comentar com es podria aplicar i que tipus de resultats es podrien obtenir. Si no ho té, reformular el problema perquè si el tingui.


## Exercici 2 (20%)
* 60%. Explicar de forma resumida com és l'objectiu dels mètodes de generació de regles d'associació. Relacionar la resposta amb un exemple.
* 40%. Raonar si té sentit aplicar un mètode de generació de regles d'associació a l'exemple que vas posar en la PEC1. Si ho té, comentar com es podria aplicar i que tipus de resultats es podrien obtenir. Si no ho té, reformular el problema perquè si el tingui.


## Exercici 3 (25%)
* 20%. S'expliquen els camps de la base de dades, preparació i anàlisi de dades
* 20%. S'aplica l'algorisme d'agrupament de manera correcta i es proven amb diferents valors de k.
* 10%. S'obté una mesura del bo que és l'agrupament.
* 40%. Es posen noms a les associacions i es descriuen i interpreten els diferents clústers obtinguts.
* 10%. Es presenta el codi i és fàcilment reproduïble.

## Exercici 4 (25%)
* 10%. Es realitza un resum de les dades incloses en la base de dades.
* 15%. Es preparen les dades de manera correcta.
* 10%. S'aplica l'algorisme de regles d'associació.
* 20%. Es realitzen diferents proves variant alguns paràmetres.
* 35%. S'expliquen les conclusions que s'obtenen.
* 10%. Es presenta el codi i és fàcilment reproduïble.

## Exercici 5 (10%)
* 25%. Es prova un algorisme diferent al kmeans.
* 25%. Es prova un altre algorisme diferent al kmeans.
* 40%. Es comparen els resultats del kmeans i els altres dos mètodes provats en aquest exercici.
* 10%. Es presenta el codi i és fàcilment reproduïble.
