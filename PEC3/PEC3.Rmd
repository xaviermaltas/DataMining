---
title: 'Mineria de dades: PEC3 - Classificació amb arbres de decisió'
author: "Autor: Jordi Escayola Mansilla"
date: "Maig 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 05.584-PAC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```
*****
# Introducció
*****
## Presentació
Aquesta prova d'avaluació contínua cobreix els Mòduls 3 (Classificació: arbres de decisió) i el Mòdul 8 (Avaluació de models) del programa de l'assignatura.

## Competències

* Ús i aplicació de les TIC en l'àmbit acadèmic i professional.
* Capacitat per a innovar i generar noves idees.
* Capacitat per a avaluar solucions tecnològiques i elaborar propostes de projectes tenint en compte els recursos, les alternatives disponibles i les condicions de mercat.
* Conèixer les tecnologies de comunicacions actuals i emergents així com saber-les aplicar convenientment per a dissenyar i desenvolupar solucions basades en sistemes i tecnologies de la informació.
* Aplicació de les tècniques específiques d'enginyeria del programari en les diferents etapes del cicle de vida d'un projecte.
* Capacitat per a aplicar les tècniques específiques de tractament, emmagatzematge i administració de dades.
* Capacitat per a proposar i avaluar diferents alternatives tecnològiques per a resoldre un problema concret.

## Objectius
La correcta assimilació del Mòdul 3. En aquesta PAC treballarem la generació i interpretació d'un arbre de decisió amb el programari de pràctiques. Seguirem amb la preparació de les dades i l'extracció inicial de coneixement.

## Descripció de la PAC a realitzar
La prova està estructurada en un total d'un únic exercici pràctic.

## Recursos Bàsics
**Material docent proporcionat per la UOC.** 

Mòdul 3 i 8 del material didàctic.

Complementaris:

* Els descrits per a l'anterior PAC.
* Fitxer titanic.csv.
* R package C5.0 (Decision Trees and Rule-Based Models): https://cran.r-project.org/web/packages/c50/index.html
* Fitxer de "German Credit": credit.csv: https://www.kaggle.com/shravan3273/credit-approval


## Criteris de valoració

Tots els exercicis han de ser presentats de forma raonada i clara, especificant tots i cadascun dels passos que s'hagin dut a terme per a la seva resolució. No s'acceptarà cap resposta que no està clarament justificada.

## Format i data de lliurament
El format de lliurament és: usernameestudiant-PECn.html/doc/docx/odt/pdf.
Es recomana el lliurament en format html i també el Rmd que genera l'html lliurat.
Data de Lliurament: 19/05/2021.
S'ha de lliurar la PAC en la bústia de lliuraments de l'aula.


## Nota: Propietat intel·lectual 

> Sovint és inevitable, en produir una obra multimèdia, fer ús de recursos creats per terceres persones. És per tant comprensible fer-ho en el marc d'una pràctica dels estudis d'Informàtica, Multimèdia i Telecomunicació de la UOC, sempre que això es documenti clarament i no suposi plagi en la pràctica. 

> Per tant, en presentar una pràctica que faci ús de recursos aliens, s'ha de presentar juntament amb ella un document en què es detallin tots ells, especificant el nom de cada recurs, el seu autor, el lloc on es va obtenir i el seu estatus legal: si l'obra està protegida pel copyright o s'acull a alguna altra llicència d'ús (Creative Commons, llicència GNU, GPL ...). 

>L'estudiant haurà d'assegurar-se que la llicència  no impedeix específicament el seu ús en el marc de la pràctica. En cas de no trobar la informació corresponent haurà d'assumir que l'obra està protegida per copyright. 

> Deureu, a més, adjuntar els fitxers originals quan les obres utilitzades siguin digitals, i el seu codi font si correspon.  

*****
# Enunciat  
*****

En aquest exercici seguirem els passos del cicle de vida d'un projecte de mineria de dades, per al cas d'un algorisme de classificació i més concretament un arbre de decisió. Primer i a tall d'exemple senzill ho farem amb l'arxiu titanic.csv, que es troba adjunt a l'aula. Aquest arxiu conté un registre per cada passatger que viatjava en el Titanic. En les variables es caracteritza si era home o dona, adult o menor (nen), en quina categoria viatjava o si era membre de la tripulació.
Es mostrarà un exemple senzill de solució amb aquestes dades però els alumnes haureu de respondre a les preguntes de la rúbrica per a un altre conjunt: German Credit. Per a aquest conjunt, prendreu com a referència la variable "default" que indica l'impagament de crèdits.

*Objectius:*

*	Estudiar les dades, per exemple: Nombre de registres del fitxer? Distribucions de valors per variables? Hi ha camps mal informats o buits?
*	Preparar les dades. En aquest cas ja estan en el format correcte i no és necessari discretizar ni generar atributs nous. Cal triar quines són les variables que s'utilitzaran per a construir el model i quina és la variable que classifica. En aquest cas la variable per la qual classificarem és el camp de si el passatger sobrevivia o no.
*	Instal·lar, si és necessari, el paquet C5.0  Es tracta d'una implementació més moderna de l'algorisme ID3 de Quinlan. Té els principis teòrics de l'ID3 més la poda automàtica. Amb aquest paquet generar un model de mineria.
*	Quina és la qualitat del model?
*	Generar l'arbre gràficament.
* Generar i extreure les regles del model.
*	En funció del model, l'arbre i les regles: Quin és el coneixement que obtenim?
*	Provar el model generat presentant-li nous registres. Classifica prou bé?

A continuació, es plantegen els punts a realitzar en la PAC 3 i, prenent com a exemple el conjunt de dades de Titanic, s'obtindran, a tall d'exemple, alguns resultats que pretendre servir a manera  d'inspiració per als estudiants.
Els estudiants hauran d'utilitzar el conjunt de dades de "German Credit Data" que es poden aconseguir en aquest enllaç: https://www.kaggle.com/shravan3273/credit-approval
  
Revisió de les dades, extracció visual d'informació i preparació de les dades

Càrrega de les dades:

```{r message= FALSE, warning=FALSE}
data<-read.csv("./titanic.csv",header=T,sep=",")
attach(data)
```

## Anàlisi inicial

Començarem fent una breu anàlisi de les dades ja que ens interessa tenir una idea general de les dades que disposem. Per això, primer calcularem les dimensions de la nostra base de dades i analitzarem quins tipus d'atributs tenim.

Per a començar, calculem les dimensions de la base de dades mitjançant la funció dim(). Obtenim que disposem de 2201 registres o passatgers (files) i 4 variables (columnes). 

```{r}
dim(data)
```

Quines són aquestes variables? Gràcies a la funció str() sabem que les quatre variables són categòriques o  discretes, és a dir, prenen valors en un conjunt finit. La variable CLASS fa referència a la classe en la qual viatjaven els passatgers (1a, 2a, 3a o crew), AGE determina si era adult o nen (Adult o Menor), la variable SEX si era home o dona (Home o Dona) i l'última variable (SURVIVED) informa si el passatger va morir o va sobreviure en l'accident (Mor o Sobreviu).

```{r}
str(data)
```

És de gran interès saber si tenim molts valors nuls (camps buits) i la distribució de valors per variables. És per això recomanable començar l'anàlisi amb una visió general de les variables. Mostrarem per a cada atribut la quantitat de valors perduts mitjançant la funció summary. 

```{r}
summary(data)
```

Com a part de la preparació de les dades, mirarem si hi ha valors missing.

```{r}
missing <- data[is.na(data),]
dim(missing)
```

Observem fàcilment que no hi ha valors missing i, per tant, no haurem de preparar les dades en aquest sentit. En cas d'haver-los, caldria prendre decisions per a tractar les dades adequadament.

Disposem per tant d'un data frame format per quatre variables categòriques sense valors nuls. Per a un coneixement major sobre les dades, tenim al nostre abast unes eines molt valuoses: les eines de visualització. Per a aquestes visualitzacions, farem ús dels paquets ggplot2, gridExtra i grid de R. 

```{r}
if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}
if(!require(ggpubr)){
    install.packages('ggpubr', repos='http://cran.us.r-project.org')
    library(ggpubr)
}
if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}
if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}
if(!require(C50)){
    install.packages('C50', repos='http://cran.us.r-project.org')
    library(C50)
}

```

Sempre és important analitzar les dades que tenim ja que les conclusions dependran de les característiques de la mostra.

```{r}
grid.newpage()
plotbyClass<-ggplot(data,aes(CLASS))+geom_bar() +labs(x="Class", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("Class")
plotbyAge<-ggplot(data,aes(AGE))+geom_bar() +labs(x="Age", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("Age")
plotbySex<-ggplot(data,aes(SEX))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("Sex")
plotbySurvived<-ggplot(data,aes(SURVIVED))+geom_bar() +labs(x="Survived", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("blue","#008000"))+ggtitle("SURVIVED")
grid.arrange(plotbyClass,plotbyAge,plotbySex,plotbySurvived,ncol=2)

```

Clarament veiem com és la mostra analitzant la distribució de les variables disponibles. De cara als informes, és molt més interessant aquesta informació que l'obtinguda en summary, que es pot usar per a complementar.

Ens interessa descriure la relació entre la supervivència i cadascun de les variables esmentades anteriorment. Per a això, d'una banda graficaremos mitjançant diagrames de barres la quantitat de morts i supervivents segons la classe en la qual viatjaven, l'edat o el sexe. D'altra banda, per a obtenir les dades que estem graficant utilitzarem la comanda table per a dues variables que ens proporciona una taula de contingència.

```{r}
grid.newpage()
plotbyClass<-ggplot(data,aes(CLASS,fill=SURVIVED))+geom_bar() +labs(x="Class", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Class")
plotbyAge<-ggplot(data,aes(AGE,fill=SURVIVED))+geom_bar() +labs(x="Age", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Age")
plotbySex<-ggplot(data,aes(SEX,fill=SURVIVED))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Sex")
grid.arrange(plotbyClass,plotbyAge,plotbySex,ncol=2)

```

D'aquests gràfics obtenim informació molt valuosa que complementem amb les taules de contingència (llistades a baix). D'una banda, la quantitat de passatgers que van sobreviure és similar en homes i dones (homes: 367 i dones 344). No, en canvi, si tenim en compte el percentatge respecte al seu sexe. És a dir, malgrat que la quantitat de dones i homes que van sobreviure és similar, viatjaven més homes que dones (470 dones i 1731 homes), per tant, la taxa de mort en homes és molt major (el 78,79% dels homes van morir mentre que en dones aquest percentatge baixa a 26,8%). 

Referent a la classe en la qual viatjaven, els passatgers que viatjaven en primera classe van ser els únics que el percentatge de supervivència era major que el de mortalitat. El 62,46% dels viatgers de primera classe va sobreviure, el 41,4% dels quals viatjaven en segona classe mentre que dels viatgers de tercera i de la tripulació només van sobreviure un 25,21% i 23,95% respectivament. Per a finalitzar, destaquem que la presència de passatgers adults era molt major que la dels nens (2092 enfront de 109) i que la taxa de supervivència en nens va ser molt major (52,29% enfront de 31,26%), no podem obviar, en canvi, que els únics nens que van morir van ser tots passatgers de tercera classe (52 nens).

```{r}
tabla_SST <- table(SEX, SURVIVED)
tabla_SST
prop.table(tabla_SST, margin = 1)
```

```{r}
tabla_SCT <- table(CLASS,SURVIVED)
tabla_SCT
prop.table(tabla_SCT, margin = 1)
```

```{r}
tabla_SAT <- table(AGE,SURVIVED)
tabla_SAT
prop.table(tabla_SAT, margin = 1) 
```

```{r}
tabla_SAT.byClass <- table(AGE,SURVIVED,CLASS)
tabla_SAT.byClass
```

Els resultats anteriors mostren les dades de manera descriptiva, podem afegir algun test estadístic per a validar el grau de significança de la relació. La llibreria "DescTools" ens permet instal·lar-ho fàcilment.


```{r}
if(!require(DescTools)){
    install.packages('DescTools', repos='http://cran.us.r-project.org')
    library(DescTools)
}
```
```{r}
Phi(tabla_SST) 
CramerV(tabla_SST) 
```
```{r}
Phi(tabla_SAT) 
CramerV(tabla_SAT) 
```

```{r}
Phi(tabla_SCT) 
CramerV(tabla_SCT) 
```

En totes les combinacions analitzades, no es troba una relació estadística significativa.

Una alternativa interessant a les barres de diagrames, és el plot de les taules de contingència. Obtenim la mateixa informació però per a alguns analistes pot resultar més visual. 

```{r}
par(mfrow=c(2,2))
plot(tabla_SCT, col = c("black","#008000"), main = "SURVIVED vs. CLASS")
plot(tabla_SAT, col = c("black","#008000"), main = "SURVIVED vs. AGE")
plot(tabla_SST, col = c("black","#008000"), main = "SURVIVED vs. SEX")
```

El nostre objectiu és crear un arbre de decisió que permeti analitzar quin tipus de passatger del Titanic tenia probabilitats de sobreviure o no. Per tant, la variable per la qual classificarem és el camp de si el passatger va sobreviure o no. De tota manera, en imprimir les primeres (amb head) i últimes 10 (amb tail) files ens adonem que les dades estan ordenades.

```{r}
head(data,10)
tail(data,10)
```

Ens interessa "desordenar-les". Guardarem les dades amb el nou nom com "data_random".

```{r}
set.seed(1)
data_random <- data[sample(nrow(data)),]
```

## Preparació de les dades per al model

Per a la futura avaluació de l'arbre de decisió, és necessari dividir el conjunt de dades en un conjunt d'entrenament i un conjunt de prova. El conjunt d'entrenament és el subconjunt del conjunt original de dades utilitzat per a construir un primer model; i el conjunt de prova, el subconjunt del conjunt original de dades utilitzat per a avaluar la qualitat del model. 

El més correcte serà utilitzar un conjunt de dades diferent del que utilitzem per a construir l'arbre, és a dir, un conjunt diferent del d'entrenament. No hi ha cap proporció fixada respecte al nombre relatiu de components de cada subconjunt, però la més utilitzada acostuma a ser 2/3 per al conjunt d'entrenament i 1/3, per al conjunt de prova. 

La variable per la qual classificarem és el camp de si el passatger va sobreviure o no, que està en la quarta columna. D'aquesta forma, tindrem un conjunt de dades per a l'entrenament i un per a la validació.

```{r}
set.seed(666)
y <- data_random[,4] 
X <- data_random[,1:3] 
```

De manera dinàmica podem definir una manera de separar les dades en funció d'un paràmetre, en aquest cas del "split_prop".
Definim un paràmetre que controla el split de manera dinàmica en el test.

```{r}
split_prop <- 3 
max_split<-floor(nrow(X)/split_prop)
tr_limit <- nrow(X)-max_split
ts_limit <- nrow(X)-max_split+1

trainX <- X[1:tr_limit,]
trainy <- y[1:tr_limit]
testX <- X[ts_limit+1:nrow(X),]
testy <- y[ts_limit+1:nrow(X)]
```

En la segona opció podem crear directament un rang utilitzant el mateix paràmetre anterior.

```{r}
split_prop <- 3 
indexes = sample(1:nrow(data), size=floor(((split_prop-1)/split_prop)*nrow(data)))
trainX<-X[indexes,]
trainy<-y[indexes]
testX<-X[-indexes,]
testy<-y[-indexes]
```

Després d'una extracció aleatòria de casos és altament recomanable efectuar una anàlisi de dades mínim per a assegurar-nos de no obtenir classificadors esbiaixats pels valors que conté cada mostra. En aquest cas, verificarem que la proporció del supervivents és més o menys constant en els dos conjunts:

```{r}
summary(trainX);
summary(trainy)
summary(testX)
summary(testy)
```

Verifiquem fàcilment que no hi ha diferències greus que puguin esbiaixar les conclusions.

## Creació del model, qualitat del model i extracció de regles

Es crea l'arbre de decisió usant les dades d'entrenament (cal no oblidar que la variable outcome és de tipus factor):

```{r}
trainy = as.factor(trainy)
model <- C50::C5.0(trainX, trainy,rules=TRUE )
summary(model)
```

Errors mostra el número i percentatge de casos mal classificats en el subconjunt d'entrenament. L'arbre obtingut classifica erròniament 317 dels 1467 casos donats, una taxa d'error del 21.6%.

A partir de l'arbre de decisió de dues fulles que hem modelat, es poden extreure les següents regles de decisió (gràcies a rules=TRUE podem imprimir les regles directament):

SEX = "Home" → Mor. Validesa: 78,1%

CLASS "1a", "2a" i AGE = "Menor" → Sobreviu. Validesa: 95,5%

SEX = "Dona" → Sobreviu. Validesa: 74,7%

Per tant, podem concloure que el coneixement extret i croat amb l'anàlisi visual es resumeix en "les dones i els nens primer a excepció que anessis de 3a classe".

A continuació, procedim a mostrar l'arbre obtingut.

```{r}
model <- C50::C5.0(trainX, trainy)
plot(model)
```


## Validació del model amb les dades reservades
Una vegada tenim el model, podem comprovar la seva qualitat predient la classe per a les dades de prova que ens hem reservat al principi.

```{r}
predicted_model <- predict( model, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))
```

Quan hi ha poques classes, la qualitat de la predicció es pot analitzar mitjançant una matriu de confusió que identifica els tipus d'errors comesos.

```{r}
mat_conf<-table(testy,Predicted=predicted_model)
mat_conf
```

Una altra manera de calcular el percentatge de registres correctament classificats usant la matriu de confusió:

```{r}

porcentaje_correct<-100 * sum(diag(mat_conf)) / sum(mat_conf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",porcentaje_correct))

```

A més, tenim a la nostra disposició el paquet gmodels per a obtenir informació més completa:

```{r}
if(!require(gmodels)){
    install.packages('gmodels', repos='http://cran.us.r-project.org')
    library(gmodels)
}
```

```{r}
CrossTable(testy, predicted_model,prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE,dnn = c('Reality', 'Prediction'))
```

## Prova amb una variació o un altre enfocament algorítmic

En aquest apartat buscarem provar amb les variacions que ens ofereix el paquet C5.0 per a analitzar com afecten a la creació dels arbres generats. Existeixen moltes possibles variacions amb altres funcions que podeu investigar. La idea és seguir amb l'enfocament d'arbres de decisió explorant possibles opcions.
Una vegada tinguem un mètode alternatiu, hem d'analitzar com es modifica l'arbre i com afecta a la capacitat predictiva en el conjunt de test.

A continuació, utilitzem un altre enfocament per a comparar els resultats: incorpora com a novetat "adaptative boosting", basat en el treball de Rob Schapire i Yoav Freund (1999). La idea d'aquesta tècnica és generar diversos classificadors, amb els seus corresponents arbres de decisió i la seva ser de regles. Quan un nou cas serà classificat, cada classificador vota com és la classe predita. Els vots són sumats i determina la classe final.

```{r}
modelo2 <- C50::C5.0(trainX, trainy, trials = 10)
plot(modelo2)
```

En aquest cas, donada la simplicitat del conjunt d'exemple, no s'aprecien diferències, però apareixeran en dades de major complexitat i modificant el paràmetre "trials" es pot intentar millorar els resultats.

Veiem a continuació com són les prediccions del nou arbre:

```{r}
predicted_model2 <- predict( modelo2, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model2 == testy) / length(predicted_model2)))
```

Observem com es modifica lleument la precisió del model a millor.

```{r}
mat_conf<-table(testy,Predicted=predicted_model2)
mat_conf
```

Una altra manera de calcular el percentatge de registres correctament classificats usant la matriu de confusió:

```{r}

porcentaje_correct<-100 * sum(diag(mat_conf)) / sum(mat_conf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",porcentaje_correct))

```

L'algorisme C5.0 incorpora algunes opcions per a veure la importància de les variables (veure documentació per als detalls entre els dos mètodes):

```{r}
importancia_usage <- C50::C5imp(modelo2, metric = "usage")
importancia_splits <- C50::C5imp(modelo2, metric = "splits")
importancia_usage
importancia_splits
```

Curiosament i encara que el conjunt de dades és molt senzill, s'aprecien diferències en els mètodes d'importància de les variables. Es recomana en el vostre exercici millorar la visualització dels resultats amb la funció ggplo2 o similar.

# Solució de l'exercici

En aquest estudi utilitzarem algorismes de classificació, concretament arbres de dedició, per tal d'analitzar un conjunt de dades relacionades amb els impagaments de préstecs i poder predir si un sol·licitant podrà retornar un crèdit o no d'acord un conjunt d'atributs.

## Estudi de les dades d'entrada

El primer pas a realitzar en aquest estudi és el de carregar les dades i fer petit anàlisi d'aquestes.

```{r message= FALSE, warning=FALSE}
#Loading the data
data<-read.csv("./credit_kaggle.csv",header=T,sep=",")
attach(data)
```

A continuació realitzem un anàlisi de l'estat inicial de les dades i quins tipus d'atributs tenim.

* Obtenció del nombre de registres i variables. 

```{r message= FALSE, warning=FALSE}
dim(data)
```
Podem observar que el conjunt de dades disposa de *1000 registres* i *21 variables* cada un d'ells.

* Anàlisi del tipus de variables que ens trobem dins el nostre dataset per cada un del registres.

```{r message= FALSE, warning=FALSE}
str(data)
```

Seguidament farem una petita descripció de cada un dels camps i que representen. 

1.  __Checking balance__ : (_String_ ) - Rang del balanç de comprovació. En DM (Deutsche Mark).
2.  __Months load duration__ : ( _Int_ ) - Duració del crèdit.
3.  __Credit history__ : (_String_ ) - Historial de retorn de crèdits.
4.  __Purpose__ : (_String_ ) - Motiu del crèdit.
5.  __Amount__ : ( _Int_ ) - Quantitat del préstec.
6.  __Savings balance__ : (_String_ ) - Diners estalviats.
7.  __Employment length__ : (_String_ ) - Duració de l'ocupació.
8.  __Installment rate__ : ( _Int_ ) - Cost de cada quota.
9.  __Personal status__ : (_String_ ) - Estat civil. 
10.  __Other debtors__ : (_String_ ) - Indica si hi ha altres deutors.
11.  __Residence history__ : ( _Int_ ) - Historial de residencies.
12.  __Property__ : (_String_ ) - Propietats.
13.  __Age__ : ( _Int_ ) - Edat.
14.  __Installment plan__ : (_String_ ) - Indica si hi ha un pla de pagament fraccionat.
15.  __Housing__ : (_String_ ) - Habitatge. 
16.  __Existing credits__ : ( _Int_ ) - Disposa d'altres crèdits. 
17.  __Default__ : ( _Int_ ) - Impagament de crèdits.
18.  __Dependents__ : ( _Int_ ) - Disposa de persones de confiança. 
19.  __Telephone__ : (_String_ ) - Indica si té o no telèfon. 
20.  __Foreign worker__ : (_String_ ) - És o no treballador estranger.
21.  __Job__ : (_String_ ) - Tipus de feina/treballador.

* Estadisitiques bàsiques de la mostra de dades.

```{r message= FALSE, warning=FALSE}
summary(data)
```

* Observem si dins les fonts de dades disposem de valors nulls.

```{r message= FALSE, warning=FALSE}
#Collecting null values
missing <- data[is.na(data),]
dim(missing)
```

Podem observar que no tenim valors NULL.


## Anàlisi descriptiva i de correlacions

En aquest apartat elaborarem un anàlisi de certes variables de forma visual per tal de començar a observar certes correlacions entre diferents camps.

* __Amount__

El primer cap que analitzarem és el de _amount_ que representa el valor del préstec. L'anàlisi d'aquest en permetrà veure quina és la distribució de la quantitat demanada dins els diferents préstecs enregistrats a la mostra de dades.

```{r message= FALSE, warning=FALSE}
#Collecting 'amount' field data.
Amount=data['amount']

#Creating a density plot
d <- density(data$amount)
plot(d, main="Credit amount distribution")
polygon(d, col="red", border ="black")

#Creating a histogram
amount <- data$amount
h <- hist(amount, breaks = 50, col="red", xlab="DM", main="Credit amount histogram")

#Mean computation
mean(amount)
```

Un cop observats els anteriors gràfics, podem veure que majoritàriament els préstecs són de quantitats no molt elevades, és més, tal com ens indica el primer gràfic, aquests acostumen a moure's pel voltant dels 3500 DM.



* __Purpose__

A continuació farem un anàlisi del motiu del préstec. Això ens portarà entendre les necessitats de les persones que realitzaven el crèdit i també relacionar-ho amb les quantitats demanades.

```{r message= FALSE, warning=FALSE}
#Collecting 'purpose' field.
Purpose = data['purpose']

#Creating a new grid
grid.newpage()
#byPurpose plot
plotByPurpose<-ggplot(data, aes(purpose))+geom_bar() +labs(x="Purpose", y="Count") + geom_text(stat='count', aes(label=..count..), vjust=-1)
grid.arrange(plotByPurpose)
```

Observant l'histograma anterior, podem determinar que tenim 4 motius majoritaris que porten a la gent a demanar un crèdit. Aquests són:

1. Radio/TV
2. Cotxe (ja sigui nou o de segona ma)
3. Mobles
4. Negocis

A continuació ens focalitzarem en observar si per cada un d'aquests elements continuem tenint la mateixa distribució del valor del préstec com hem pogut veure anteriorment de forma més global, o cada un dels motius té una distribució particular.

```{r message= FALSE, warning=FALSE}
#Collecting topPurpose elements
topPurposeNames <- c("car (new)", "car (used)", "business", "furniture", "radio/tv")
topPurpose=subset(data, purpose %in% topPurposeNames)

#'amount' histogram per each topPurpose element
ggplot(topPurpose, aes(amount)) + geom_histogram(aes(color = amount), bins=20)+facet_wrap(~purpose)

#Mean computation
mean(topPurpose$amount)
```

Un cop realitzada la segmentació pels motius principals, podem concloure que tot i que la densitat per a cada un dels casos no és exactament igual al gràfic global en termes de la quantitat del préstec, aquests s'hi assemblen bastant. A la vegada, també és fàcilment visible que el valor mitjà és pràcticament el mateix, al voltant dels 3500 DM.

## Primer arbre de decisió

El primer pas a realitzar per tal de crear el nostre arbre de decisió serà la divisió del conjunt de dades entre el conjunt d'entrenament i el conjunt de test. El conjunt d'entrenament ens permetrà entrenar el nostre model, mentre que el conjunt de test, ens permetrà verificar el funcionament del model i avaluar la qualitat d'aquest.

```{r message= FALSE, warning=FALSE}
#Creating a seed
set.seed(101)
#Creating training indexes
train_indexes <- sample(1000, 800)
#Create training sample
credit_train <- data[train_indexes, ]
#Creating test sample
credit_test  <- data[-train_indexes, ]
```

El factor que desitgem predir correspon al camp _'default'_ de les nostres dades, és per això que és necessari veure quina és la relació d'aquests valors a la mostra global, i si aquesta és més o menys similar també als conjunts d'entrenament i de test.

```{r message= FALSE, warning=FALSE}
#'default' global sample
table(data$default)
#'default' train sample distribution
prop.table(table(credit_train$default))
#'default' test sample distribution
prop.table(table(credit_test$default))
```

Les particions obtingudes són bastant representatives en el camp _'default'_, ja que es mouen molt a prop al 70-30 (%) de la mostra global.

A continuació carregarem la llibreria C50 i crearem el nostre model classificador basat en un arbre de decisió.
Un pas previ que haurem de realitzar, és el de convertir a _factor_ el camp _'default'_, ja que és un requeriment d'entrada per a crear el model.

```{r message= FALSE, warning=FALSE}
#Load of C50 library
library(C50)
#'default' to a factor
credit_train$default<-as.factor(credit_train$default)
#Model creation
model <- C50::C5.0(credit_train[-17], credit_train$default,rules = TRUE)
#Summary of the model
summary(model)
```

Mitjançant la funció _summary()_ podrem veure la informació detallada de l'arbre de decisió com podria el percentatge d'error a l'hora de classificar, la quantitat d'elements utilitzats per a realitzar l'entrenament, com s'han classificat, entre d'altres moltes dades. Un element molt rellevant que també podem observar són les regles de decisió dins el nostre arbre classificador.
En aquest cas hi trobem 23 regles de decisió. Aquestes ens indiquen segons una combinació d'atributs d'entrada quin és el valor de sortida més probable que surti i amb quina probabilitat en un rang d'entre 0 i 1.
També podem visualitzar de forma molt més gràfica l'arbre de decisió que hem obtingut. En el nostre cas, donada la gran quantitat d'atributs amb els quals estem treballant, és realment complicat d'interpretar, ja que la majoria de valors se superposen.

```{r message= FALSE, warning=FALSE}
#Plot the decision tree of the model
model <- C50::C5.0(credit_train[-17], credit_train$default)
plot(model)
```

## Explicació de les regles obtingudes

Les regles de decisió del model són les que ens permeten realitzar la classificació de les dades d'entrada. La llibreria _C50_ elabora un anàlisi dels valors d'entrenament i el valor a predir, i genera un model predicatiu de classificació per a futures dades d'entrada.
Tal com hem dit anteriorment, el nombre de regles de decisió per aquest cas és d'un total de 23.
L'algorisme, principalment les ha separat en si la sortida tendeix a ser 1 o si tendeix a ser 2.

* __Predicció = 1__

Disposem de 4 d'un total de 23 regles que fan referència amb una alta probabilitat que surti com a valor predit 1.

Aquestes regles es focalitzen a una temporalitat del préstec a mitjà termini (2-4 anys), no molts diners estalviats o a vegades indefinits i amb un historial de crèdits gens favorable.
Segons la interpretació de les regles podem deduir que la predicció fa referència al no retornament de préstec.

* __Predicció = 2__

Per altra banda, disposem de 19 regles que fan referència a que el valor predit sigui 2. 

Les regles de decisió d'aquest cas principalment es focalitzen a historials de crèdit força favorables i majoritàriament amb una feina estable. Pel que fa als altres aspectes, tendeixen a ser variats com que disposem de moltes regles que fan referència aquest valor. Així i tot, un dels dos factors anteriorment comentats apareix gairebé sempre.

## Anàlisis de la bondat d'ajust sobre el conjunt de test i matriu de confusió

Un factor transcendental en el camp dels models predictius és l'avaluació del rendiment i la qualitat del nostre model.

A continuació realitzarem una prova al model amb les dades de test separades anteriorment.

```{r message= FALSE, warning=FALSE}
#Precision computation
predicted_model <- predict(model, credit_test, type="class")
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == train_indexes) / length(predicted_model)))
summary(predicted_model)
```

Després de realitzar la prova, podem veure que la precisió del model és d'un 50% d'efectivitat.
Una altra forma molt útil per identificar i analitzar els errors comesos és la matriu de confusió. Aquesta ens indica el valor predit respecte al valor real. D'aquesta manera podem veure quantes vegades hem fallat de cada element i envers quin altre ho hem fet. Aquest procés ens porta a millor el nostre classificador per tal que sigui més precís.

```{r message= FALSE, warning=FALSE}
if(!require(gmodels)){
  install.packages('gmodels', repos='http://cran.us.r-project.org')
  library(gmodels)
}
CrossTable(credit_test$default, predicted_model,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('Reality', 'Predicted'))

```

## Models complementaris

En aquest apartat comprovarem si obtenim algun tipus de millor en el rendiment de l'efectivitat del nostre model aplicant el concepte del "adaptative boosting".

```{r message= FALSE, warning=FALSE}
#New model creation
model2 <- C50::C5.0(credit_train[-17], credit_train$default, trials=10, rules = TRUE)
#summary(model2)
```


```{r message= FALSE, warning=FALSE}
#New model testing
predicted_model2 <- predict(model2, credit_test, type="class")
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model2 == train_indexes) / length(predicted_model2)))

#New model confusion matrix
CrossTable(credit_test$default, predicted_model2,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('Reality', 'Predicted'))
```

Després de realitzar la prova amb aquesta nova variant utilitzant la llibreria C5.0, veiem que els resultats en termes d'efectivitat són exactament els mateixos. 

## Conclusions obtingudes

L'estudi realitzat ha sigut molt interessant en múltiples aspectes. Principalment la consolidació dels conceptes teòrics de l'assignatura respecte als models de classificació amb arbres de decisió. A la vegada, personalment observo que començo a agafar molt més pràctica en el llenguatge de programació R que era completament nou per a mi. També comentar que m'ha semblat molt interessant tractar amb aquest tipus de dades, ja que és un possible cas real amb el qual un futur ens hi podem trobar, però també he pogut observar que aquesta classe d'algorismes que hem utilitzat són molt poc eficients per casos on la quantitat d'atributs tendeix a ser gran, ja que la seva predicció és del tipus 'ruled based' i tal com ens hem trobat en aquest cas, la quantitat de regles creix molt ràpidament i tendeixen a ser poc concises tal com hem vist en l'anàlisi de la predicció 2.

******
# Rúbrica
******
* (Obligatori) S'ha de realitzar un breu informe (PDF, Html.... ) on es responguin a les preguntes concretes, mostrant en primer lloc el codi utilitzat, després els resultats i posteriorment els comentaris que es considerin pertinents per a cada apartat.  
* 10% Hi ha un estudi sobre les dades dels quals es parteix, les variables que componen les dades. Les dades són preparades correctament.
* 10% Es realitza una anàlisi descriptiva univariant (o anàlisi de rellevància) d'algunes variables una vegada s'han tractat vs el target a nivell gràfic, comentant les que aparentment són més interessants. Anàlogament es realitza una anàlisi de correlacions.
* 20% S'aplica un arbre de decisió de manera correcta i s'obté una estimació de l'error, mostrant gràficament l'arbre obtingut. La visualització ha de ser comprensible i adequada al problema a resoldre.
* 15% S'expliquen les regles que s'obtenen en termes concrets del problema a resoldre.
* 15% S'usa el model per a predir amb mostres no usades en l'entrenament (holdout) i s'obté una estimació de l'error. Sobre la base de la matriu de confusió, es comenten els tipus d'errors i es valora de forma adequada la capacitat predictiva de l'algorisme.
* 15% Es prova un altre model d'arbre o variants diferents del C50 i es comparen els resultats obtinguts, valorant si són millors.
* 10% Es presenta unes conclusions on s'exposa un resum dels diferents models utilitzats (almenys 3) així com el coneixement adquirit després del treball realitzat i els descobriments més importants realitzats en el conjunt de dades.
* 5% Es presenta el codi i és fàcilment reproduïble.

